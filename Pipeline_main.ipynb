{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0967122-8604-447d-b75f-fbd846aec3e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import dendropy\n",
    "from dendropy.calculate import treecompare\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import Bio\n",
    "import glob\n",
    "%matplotlib inline\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67bcd948-ed1f-4856-b2f1-a872cc495b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurm = \"\"\"#!/usr/bin/bash\n",
    "#input file name in command line\n",
    "#SBATCH --job-name=new      # Job name\n",
    "#SBATCH --mail-type=END,FAIL         # Mail events (NONE, BEGIN, END, FAIL, ALL)\n",
    "#SBATCH --mail-user=xxxxx@email.edu    # Where to send mail.  Set this to your email address\n",
    "#SBATCH --account=xxxx\n",
    "#SBATCH --qos=xxxx\n",
    "#SBATCH --ntasks=1                  # Number of MPI tasks (i.e. processes)\n",
    "#SBATCH --cpus-per-task=2            # Number of cores per MPI task\n",
    "#SBATCH --nodes=1                    # Maximum number of nodes to be allocated\n",
    "#SBATCH --ntasks-per-node=1         # Maximum number of tasks on each node\n",
    "#SBATCH --mem=8gb          # Memory (i.e. RAM) per processor\n",
    "#SBATCH --time=3-00:00:00              # Wall time limit (days-hrs:min:sec)\n",
    "#SBATCH --output=mpi_test_%j.log     # Path to the standard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b07a5f-9aa6-4bf6-ad15-c089e88d0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./SNAP_3/sample_101123.list\",sep=\"\\t\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad8639-206c-420d-8c0f-2a8fa684d32a",
   "metadata": {},
   "source": [
    "## Build an index for SNAP aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e316ff-e76e-48eb-9611-207545e8a4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script = \"\"\"ml snap/2.0.3\n",
    "snap-aligner index VescaGenome/Fragaria_vesca_v6_genome.fasta.gz VescaGenome/Fvesca\"\"\"\n",
    "subprocess.run(script, shell = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b2f1a-c178-4d66-aca2-425b7b0eb495",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Align diploid species to F.vesca genome using SNAP aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdf9b5-7308-45ec-9f2a-ad95e4013076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_dir='VescaGenome/Fvesca'\n",
    "for index, row in df.iterrows():\n",
    "    if os.path.isfile('./SNAP_3/{}.bam'.format(row[0])):\n",
    "        print('./SNAP_3/{}.bam exists'.format(row[0]))\n",
    "    else:    \n",
    "        if pd.isna(row['File3']) == True:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} -pre- -so -o ./SNAP_3/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],id=row[0])\n",
    "        else:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} {file3} {file4} -pre- -so -o ./SNAP_3/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],\n",
    "                                                                                                                                        file3=row['File3'],file4=row['File4'],id=row[0])\n",
    "        script_file = \"{}_SNAP.sh\".format(row[0])\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script)\n",
    "        result = subprocess.run(['sbatch', script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7097d0-801c-493a-8162-6453c04ded89",
   "metadata": {},
   "source": [
    "## Alternative pipeline for sorting and indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657b8fc-bc8d-486b-b734-7bf13423a643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_dir='VescaGenome/Fvesca'\n",
    "for index, row in df.iterrows():\n",
    "    if os.path.isfile('./SNAP_3/{}.bam'.format(row[0])):\n",
    "        print('./SNAP_3/{}.bam exists'.format(row[0]))\n",
    "    else:    \n",
    "        if pd.isna(row['File3']) == True:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} -o ./SNAP_3/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],id=row[0])\n",
    "        else:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} {file3} {file4} -o ./SNAP_3/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],\n",
    "                                                                                                                                        file3=row['File3'],file4=row['File4'],id=row[0])\n",
    "        script = script + \"\\nml samtools\" + \"\\nsamtools sort ./SNAP_3/{id}.bam > ./SNAP_3/{id}_sort.bam \".format(id=row[0]) + \\\n",
    "            \"\\nmv ./SNAP_3/{id}_sort.bam ./SNAP_3/{id}.bam\".format(id=row[0]) + \\\n",
    "            \"\\nsamtools index ./SNAP_3/{id}.bam\".format(id=row[0])\n",
    "        script_file = \"{}_SNAP.sh\".format(row[0])\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script)\n",
    "        result = subprocess.run(['sbatch', script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aafeb3d-2330-47b3-924e-7783b0721cd2",
   "metadata": {},
   "source": [
    "## Simulate short reads for subgenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b14ad2-0557-465a-b4e3-2659d1f58bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate reads for subgenomes\n",
    "ml=\"\\nml seqkit\" + \"\\nml art\"\n",
    "# grep subgenome\n",
    "for subgenome, ID in zip([\"C\",\"D\"],[\"C\",\"D\"]):\n",
    "    for file in [\"./Genomes/Fchil_hap1.fa.gz\",\"./Genomes/Fvirg_hap1.fa.gz\"]:\n",
    "        prefix = re.match(\".+(F.*)_.*\",file).group(1)\n",
    "        output = \"{prefix}_{ID}.fasta\".format(prefix = prefix,ID=ID)\n",
    "        getsubfasta = \"\\nseqkit grep -n -r -p {subgenome} {file} > {output} \".format(subgenome=subgenome,file=file, output=output)\n",
    "        ##get names for the simReads\n",
    "        out_fastq = \"{prefix}_{ID}_sim\".format(prefix = prefix,ID=ID)\n",
    "        simreads = \"\\nart_illumina -ss HSXt -p -l 150 -f 40 -m 200 -s 0 -i {} -o {} \".format(output,out_fastq)\n",
    "        script = slurm + ml+getsubfasta+simreads\n",
    "        script_file = \"{}_SNAP.sh\".format(out_fastq)\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script)\n",
    "        subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f1435-df4e-4455-ab1c-b51455e0e5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate reads for subgenomes\n",
    "ml=\"\\nml seqkit\" + \"\\nml art\"\n",
    "# grep subgenome\n",
    "for subgenome, ID in zip([\"A\",\"B\"],[\"A\",\"B\"]):\n",
    "    for file in [\"./Genomes/Fchil_hap1.fa.gz\",\"./Genomes/Fvirg_hap1.fa.gz\"]:\n",
    "        prefix = re.match(\".+(F.*)_.*\",file).group(1)\n",
    "        output = \"{prefix}_{ID}.fasta\".format(prefix = prefix,ID=ID)\n",
    "        getsubfasta = \"\\nseqkit grep -n -r -p {subgenome} {file} > {output} \".format(subgenome=subgenome,file=file, output=output)\n",
    "        ##get names for the simReads\n",
    "        out_fastq = \"{prefix}_{ID}_sim\".format(prefix = prefix,ID=ID)\n",
    "        simreads = \"\\nart_illumina -ss HSXt -p -l 150 -f 40 -m 200 -s 0 -i {} -o {} \".format(output,out_fastq)\n",
    "        script = slurm + ml+getsubfasta+simreads\n",
    "        script_file = \"{}_SNAP.sh\".format(out_fastq)\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script)\n",
    "        subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cac27-1ea6-4cc4-a39f-f953bf51a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for FL158925\n",
    "ml=\"ml seqkit\" + \"\\nml art\"\n",
    "chrCb = [\"Fvb\" + item + \"_B\\n\" for item in [\"1-1\",\"2-1\",\"3-1\",\"4-1\",\"5-4\",\"6-2\",\"7-4\"]] \n",
    "chrCa = [\"Fvb\" + item + \"_B\\n\" for item in [\"1-3\",\"2-3\",\"3-3\",\"4-2\",\"5-2\",\"6-4\",\"7-1\"]]\n",
    "chrA = [\"Fvb\" + item + \"_B\\n\" for item in ['1-4','2-2','3-4','4-3','5-1','6-1','7-2']] \n",
    "chrB = [\"Fvb\" + item + \"_B\\n\" for item in ['1-2','2-4','3-2','4-4','5-3','6-3','7-3']] \n",
    "\n",
    "# grep subgenome\n",
    "for subgenome,ID in zip([chrCb,chrCa,chrA,chrB],['Cb','Ca','A','B']):\n",
    "    file = '{}.chr_list'.format(ID) \n",
    "    with open(file,\"w\") as f:\n",
    "        f.writelines(subgenome)\n",
    "    output = \"{prefix}_{ID}.fasta\".format(prefix = 'Fxa',ID=ID)\n",
    "    getsubfasta = \"\\nseqkit grep -n -f {file} /orange/seonghee/15.89-25_Genome/Beauty.hap.fasta > {output} \".format(file=file, output=output)\n",
    "    ##get names for the simReads\n",
    "    out_fastq = \"{prefix}_{ID}_sim\".format(prefix = 'Fxa',ID=ID)\n",
    "    simreads = \"\\nart_illumina -ss HSXt -p -l 150 -f 40 -m 200 -s 0 -i {} -o {} \".format(output,out_fastq)\n",
    "    script = slurm + ml+getsubfasta+simreads\n",
    "    script_file = \"{}.sh\".format(out_fastq)\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)\n",
    "    subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76296a9d-3396-476d-9e00-2ecff9c52002",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variant calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08271414-ec0c-44aa-8e98-3a9e9fbaf52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml=\"\\nml gatk\"\n",
    "haplocaller_script = \"\"\"\n",
    "gatk --java-options \"-Xmx32g\" HaplotypeCaller  \\\n",
    "         -R /orange/whitaker/zhen/Polyorigin/VescaGenome/Fragaria_vesca_v6_genome.fasta \\\n",
    "         --native-pair-hmm-threads 8 \\\n",
    "         -L chr.list \\\n",
    "         -I {file} \\\n",
    "         -O {id}.g.vcf.gz \\\n",
    "         -ERC GVCF\n",
    "\"\"\"\n",
    "\n",
    "all_files_and_dirs = os.listdir(\"./SNAP_3/\")\n",
    "bam_files = [f for f in all_files_and_dirs if re.fullmatch(\".+bam\",f) ]\n",
    "for bam_file in bam_files:\n",
    "    id1 = re.match(\"(^.+).bam\",bam_file).group(1)\n",
    "    script = haplocaller_script.format(file = \"./SNAP_3/\" + bam_file, id = \"./GVCF/\"+ id1)\n",
    "    script = slurm + ml + script\n",
    "    script_file = \"{}_hapcall.sh\".format(id1)\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)\n",
    "    subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55eb2b7-26ef-43f3-9a85-7a0cb399cb3c",
   "metadata": {},
   "source": [
    "## Merge GVCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485499f-091a-4641-ad8d-73a91fcf6f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml=\"\\nml gatk\"\n",
    "CombineGVCFs_script = \"\"\"\n",
    "gatk CombineGVCFs \\\n",
    "   -R /blue/whitaker/fanzhen/asm/farr1.fa \\\n",
    "   --variant GVCF/ERR2003066.g.vcf.gz \\\n",
    "   --variant GVCF/ERR2008847.g.vcf.gz \\\n",
    "   --variant GVCF/ERR2008776.g.vcf.gz \\\n",
    "   --variant GVCF/ERR2008777.g.vcf.gz \\\n",
    "   --variant GVCF/ERR2008844.g.vcf.gz \\\n",
    "   --variant GVCF/ERR2008845.g.vcf.gz \\\n",
    "   -O GVCF/PMi.g.vcf.gz\"\"\"\n",
    "script = slurm + ml + CombineGVCFs_script\n",
    "script_file = \"CombineGVCFs.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245bc5e4-ae20-4eba-aeb6-33ab914f3b43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GenomicsDBImport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05571166-719b-4ce1-831b-cfdb8c939cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"GVCF\"] = \"GVCF/\" + df.iloc[:,0] + \".g.vcf.gz\"\n",
    "df_map = df.loc[:,[\"New Name\",\"GVCF\"]]\n",
    "df_map.to_csv('GVCFmap.csv', index=False, header=False, quoting=3,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e3f02-2889-4136-adae-86946b810bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml=\"\\nml gatk\"\n",
    "genomicDB_script = \"\"\"\\ngatk --java-options \"-Xmx100g -Xms100g\" \\\n",
    "       GenomicsDBImport \\\n",
    "       --genomicsdb-workspace-path {db_path} \\\n",
    "       -L chr.list \\\n",
    "       --sample-name-map {map} \\\n",
    "       --reader-threads 7 \\\n",
    "        --max-num-intervals-to-import-in-parallel 10 \\\n",
    "        --genomicsdb-shared-posixfs-optimizations \\\n",
    "        --batch-size 16 \\\n",
    "        --tmp-dir /orange/whitaker/zhen/popgen/tmp/\n",
    "\"\"\"\n",
    "script = slurm + ml + genomicDB_script.format(map = 'GVCFmap.csv', db_path= \"GDB/\")\n",
    "script_file = \"GenomicsDBImport.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542a04f-94f6-4477-bd42-50de70466933",
   "metadata": {},
   "source": [
    "## GenotypeGVCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552e60a-9fc8-4761-aba2-2a5bc9fdca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml=\"\\nml gatk\"\n",
    "GVCF_script = \"\"\"\n",
    "gatk --java-options \"-Xmx32g\" GenotypeGVCFs \\\n",
    "   -R /orange/whitaker/zhen/Polyorigin/VescaGenome/Fragaria_vesca_v6_genome.fasta\\\n",
    "   -V gendb://GDB \\\n",
    "   -O raw.40w.vcf.gz \\\n",
    "   -L chr.list \\\n",
    "   --genomicsdb-shared-posixfs-optimizations\n",
    "   \"\"\"\n",
    "script = slurm + ml + GVCF_script\n",
    "script_file = \"GVCF.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afc112-32e7-4fc7-a863-2a9cc60c829c",
   "metadata": {},
   "source": [
    "## Hard filtering of SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a60d2f-f6f5-40c1-ab36-6443efdc9138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Filter using GATK\n",
    "ml=\"\\nml gatk\"\n",
    "Filtering_script = \"\"\"\n",
    "gatk VariantFiltration \\\n",
    "    -V raw.40w.vcf.gz \\\n",
    "   --filter-name \"QUAL30\" -filter \"QUAL < 30.0\" \\\n",
    "   --filter-name \"QD2\"  -filter \"QD < 2.0\"  \\\n",
    "   --filter-name \"FS55\" -filter \"FS > 55.0\"  \\\n",
    "        --filter-name \"SOR3\" -filter \"SOR > 3.0\"  \\\n",
    "         --filter-name \"MQ55\" -filter \"MQ < 55.0\"  \\\n",
    "        --filter-name \"MQR_2\" -filter \"MQRankSum < -2.0\"  \\\n",
    "        -O filter.40w.vcf.gz\n",
    "\"\"\"\n",
    "script = slurm + ml + Filtering_script\n",
    "script_file = \"Filtering_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a614c-1938-49f8-ad9e-d1ac54077115",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Additional filtering steps\n",
    "ml = \"\\nml bcftools\"\n",
    "filter1 = \"\"\"\\nbcftools view -i'FILTER=\"PASS\" && F_MISSING<0.3' --no-update -Oz < filter.40w.vcf.gz  > passed.40w.vcf.gz\"\"\"\n",
    "filterSNP = \"\"\"\\nbcftools view -i'TYPE=\"snp\" && N_ALT=1' -Oz  passed.40w.vcf.gz  > SNP.40w.vcf.gz\"\"\"\n",
    "indexSNP = \"\"\"\\nbcftools index SNP.40w.vcf.gz\"\"\"\n",
    "#filterLD = \"\"\"\\nbcftools view -R ../popgen/farr1.intron.only.bed -Oz SNP.38w.vcf.gz > SNP.38w.intron.vcf.gz \n",
    "#bcftools +prune -m 0.4 -w 1000 --nsites-per-win-mode maxAF -Oz SNP.38w.intron.vcf.gz -o SNP.intron.04.38w.vcf.gz\"\"\"\n",
    "script = slurm + ml + filter1 + filterSNP + indexSNP \n",
    "#script = slurm + ml +  filterSNP + indexSNP + filterLD\n",
    "script_file = \"Filtering2_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2dd5d6-17f3-49f0-a4d7-70a144266294",
   "metadata": {},
   "source": [
    "## Concatenated species tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95f3ad-f5a9-4ff9-a987-9ed0b41a9db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vcf2phy = \"\"\"\n",
    "ml python\n",
    "python ../popgen/vcf2phylip/vcf2phylip/vcf2phylip.py -i SNP.40w.vcf.gz --nexus\"\"\"\n",
    "iqtree = \"\"\"\n",
    "ml iq-tree\n",
    "iqtree2 -s SNP.40w.min4.phy -B 1000 -T AUTO --prefix SNP.40w -alrt 1000 -m MFP -T AUTO -redo\n",
    "\"\"\"\n",
    "script = slurm + vcf2phy + iqtree\n",
    "script_file = \"iqtree_full_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743846d-ec6f-447c-b493-4594ccd5678a",
   "metadata": {},
   "source": [
    "## 10k-variant window, Astral and SVDq trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639768b-2c98-46de-bea9-a98accc43e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##produce a partition file \n",
    "l1=list(range(1,1611))\n",
    "l2=list(range(1,16104631,10000))\n",
    "l3=list(range(10000,16114631,10000))\n",
    "l4 = [\"DNA, part\" + str(a) + \" = \" + str(b) + \"-\" + str(c) for a,b,c in zip(l1,l2,l3)]\n",
    "with open('partition.txt', 'w') as file:\n",
    "    for item in l4:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77585a18-03a7-4ac6-bb67-bfeadc613261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##build gene trees\n",
    "ml = \"\\nml iq-tree\"\n",
    "tree = \"\"\"\\niqtree2 -s SNP.40w.min4.phy -S partition.txt --prefix Genetree/loci -T AUTO\"\"\"\n",
    "script = slurm + ml + tree\n",
    "script_file = \"genetree_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2a0f9-c026-4217-b361-620302adcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ASTRAL tree\n",
    "\"java -jar astral.5.7.8.jar -i in.tree -o out.tre 2>out.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c1fa0-724d-4408-8195-511b0a96078f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##SVD quartz\n",
    "##build nex file \n",
    "script_file = \"species.nex\"\n",
    "start = \"\"\"#NEXUS\n",
    "begin paup;\n",
    "        cd *;\n",
    "        set hashcomment=y;\n",
    "end;\n",
    "execute {alnfile};\n",
    "begin sets;\n",
    "charpartition lociset =\n",
    "\"\"\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(start.format(alnfile=\"SNP.40w.min4.nexus\"))\n",
    "l1=list(range(1,1611))\n",
    "l2=list(range(1,16104631,10000))\n",
    "l3=list(range(10000,16114631,10000))\n",
    "l4 = [str(a) + \" : \" + str(b) + \"-\" + str(c) + \",\" for a,b,c in zip(l1,l2,l3)]\n",
    "with open(script_file, 'a') as file:\n",
    "    for item in l4:\n",
    "        file.write(f\"{item}\\n\")\n",
    "end = \"\"\"end;\n",
    "begin paup;\n",
    "outgroup Rchinensis;\n",
    "svdq loci=lociset bootstrap=multilocus showScores=no seed=123 treeFile=SVDQ/species_SVDQ.tre ;\n",
    "#save bootstrap values\n",
    "rootTrees rootMethod=outgroup;\n",
    "contree all/strict=no majrule=yes usetreewts=yes treefile=svdq.boot.tre;\n",
    "end;\n",
    "quit;\n",
    "\"\"\"\n",
    "with open(script_file, \"a\") as f:\n",
    "    f.write(end)\n",
    "##change \",\" after last charpartition lociset to \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bbe98-6f00-4def-970b-5c7d3e1c97dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##run svdq\n",
    "script = \"\"\"ml paup/4.0a168\n",
    "paup species.nex\"\"\"\n",
    "script = slurm + script\n",
    "script_file = \"sdvq.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7baf141-a3c0-4d60-969a-7608b50664d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 34656631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', 'astral.sh'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##run astral\n",
    "script = \"\"\"ml astral\n",
    "astral -i Genetree/loci.treefile -o Astral/astral.tre 2>Astral/astral.log\"\"\"\n",
    "script = slurm + script\n",
    "script_file = \"astral.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089bd90-7d7d-4dcc-964b-8e78f9c69f41",
   "metadata": {},
   "source": [
    "## add gCF to each branch of species tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8fdd6-3d29-416f-8f7b-f5f1cad77047",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Gene concordance factor (gCF)\n",
    "ml = \"\\nml iq-tree/2.2.2.7\"\n",
    "tree = \"\"\"iqtree2 -t contree/SNP.40w.treefile --gcf Genetree/loci.treefile --prefix contree/concord\"\"\"\n",
    "script = slurm + ml + tree\n",
    "script_file = \"gcf_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f8e9b-0160-41d9-afb6-0cec4b2d276d",
   "metadata": {},
   "source": [
    "## Treemix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddfb0a-8cb1-4055-ba22-4b30fa184def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script = \"\"\"ml bcftools\n",
    "bcftools view -S treemix/short.list -Oz SNP.40w.vcf.gz > SNP.32w.vcf.gz\"\"\"\n",
    "subprocess.run(script,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b643495-d783-4022-bbe7-17608e0caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bash command s\n",
    "##./vcf2treemix.sh ../SNP.32w.vcf.gz name.clust\n",
    "##run treemix with -k 500\n",
    "ml = \"\\nml treemix\"\n",
    "script = \"\\ntreemix -i treemix/SNP.32w.treemix.frq.gz -k 500 -m {} -seed {} -bootstrap -root Rchinensis -o treemix/treemix_073024/{}_s{}.treemix\"\n",
    "for i in range(2,4):\n",
    "    for s in range(1,21):\n",
    "        script1 = slurm + ml + script.format(i,s,i,s)\n",
    "        script_file = \"treemix_script_{}_s{}.sh\".format(i,s)\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script1)\n",
    "        subprocess.run(['sbatch',script_file])\n",
    "##has to run treemix with the right tf after getting the optimum migration edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b70fe-0afe-48a9-bf9b-5eeadb34a23f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PhyloNet tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9fd79b-c36f-4f4f-9635-58f76a70be06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 35360988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', 'PhyloNetM.sh'], returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import Phylo\n",
    "import re\n",
    "# some samples will be removed from tree.\n",
    "prune_list = ['bracteata_1','bracteata_E1','bracteata_E2','viridis_3','vesca_3','bracteata_3','mandschurica_1','mandschurica_2','mandschurica_3']\n",
    "# Function to convert tree file to NEXUS format and remove TaxLabels\n",
    "def convert_to_nexus(input_file, output_file):\n",
    "    # Read the trees from the input file\n",
    "    trees = list(Phylo.parse(input_file, 'newick'))\n",
    "    ##prune tree using a list of taxa\n",
    "    subtrees = list()\n",
    "    for tree in trees:\n",
    "        for taxon in prune_list:\n",
    "            if tree.find_any(name=taxon):\n",
    "                tree.prune(taxon)\n",
    "    # Write the trees to a temporary NEXUS file\n",
    "    temp_output_file = 'temp_output_file.nex'\n",
    "    Phylo.write(trees, temp_output_file, 'nexus')\n",
    "    \n",
    "    # Read the temporary NEXUS file\n",
    "    with open(temp_output_file, 'r') as file:\n",
    "        nexus_content = file.read()\n",
    "    \n",
    "    # Remove the TaxLabels block using regex\n",
    "    nexus_content = re.sub(r'Begin Taxa;.*?End;', '', nexus_content, flags=re.DOTALL)\n",
    "    \n",
    "    # Write the modified content to the final output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(nexus_content)\n",
    "\n",
    "# Example usage\n",
    "input_file = './Genetree/loci.treefile'  # replace with your input file name\n",
    "output_file = './PhyloNet/locitree_noMan.nex'  # replace with your desired output file name\n",
    "convert_to_nexus(input_file, output_file)\n",
    "phy_script = \"\"\"\n",
    "BEGIN PHYLONET;\n",
    "InferNetwork_MP (all) 3 -n 3 -pl 16 -di -a <iinumae:iinumae_1,iinumae_2,iinumae_3;nilgerrensis:nilgerrensis_1,nilgerrensis_2;nipponica:nipponica_1,nipponica_2;bracteata1:americana,bracteata_F;bracteata2:bracteata_2,bracteata_4,bracteata_5;vesca:vesca_1,vesca_2,alba;viridis:viridis_1,viridis_2;octoploid_A:ananassa_A,chiloensis_A,virginiana_A;octoploid_B:ananassa_B,chiloensis_B,virginiana_B;octoploid_Ca:ananassa_Ca,chiloensis_Ca,virginiana_Ca;octoploid_Cb:ananassa_Cb,chiloensis_Cb,virginiana_Cb;Pmicrophylla:Pmicrophylla;Rchinensis:Rchinensis> ;\n",
    "InferNetwork_MPL (all) 3 -pl 16 -di -a <iinumae:iinumae_1,iinumae_2,iinumae_3;nilgerrensis:nilgerrensis_1,nilgerrensis_2;nipponica:nipponica_1,nipponica_2;bracteata1:americana,bracteata_F;bracteata2:bracteata_2,bracteata_4,bracteata_5;vesca:vesca_1,vesca_2,alba;viridis:viridis_1,viridis_2;octoploid_A:ananassa_A,chiloensis_A,virginiana_A;octoploid_B:ananassa_B,chiloensis_B,virginiana_B;octoploid_Ca:ananassa_Ca,chiloensis_Ca,virginiana_Ca;octoploid_Cb:ananassa_Cb,chiloensis_Cb,virginiana_Cb;Pmicrophylla:Pmicrophylla;Rchinensis:Rchinensis> ;\n",
    "InferNetwork_ML_Bootstrap (all) 3 -pl 16 -di -a <iinumae:iinumae_1,iinumae_2,iinumae_3;nilgerrensis:nilgerrensis_1,nilgerrensis_2;nipponica:nipponica_1,nipponica_2;bracteata1:americana,bracteata_F;bracteata2:bracteata_2,bracteata_4,bracteata_5;vesca:vesca_1,vesca_2,alba;viridis:viridis_1,viridis_2;octoploid_A:ananassa_A,chiloensis_A,virginiana_A;octoploid_B:ananassa_B,chiloensis_B,virginiana_B;octoploid_Ca:ananassa_Ca,chiloensis_Ca,virginiana_Ca;octoploid_Cb:ananassa_Cb,chiloensis_Cb,virginiana_Cb;Pmicrophylla:Pmicrophylla;Rchinensis:Rchinensis> ;\n",
    "END;\n",
    "\"\"\"\n",
    "with open(output_file, 'a') as file1:\n",
    "    # Writing data to a file\n",
    "    file1.write(phy_script)\n",
    "##run PHYLONET\n",
    "##multiple alleles per sample did not work \n",
    "script = \"\"\"\n",
    "ml phylonet\n",
    "PhyloNet ./PhyloNet/locitree_noMan.nex\"\"\"\n",
    "script = slurm + script\n",
    "script_file = \"PhyloNetM.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c104d48-52cf-41f9-a804-c0638e407f5d",
   "metadata": {},
   "source": [
    "## Phylonet with variable hybridization edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1f282d-9dfe-45fa-9556-81f39d6c3985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 35414335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', 'PhyloNetM.sh'], returncode=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import Phylo\n",
    "import re\n",
    "prune_list = ['bracteata_1','bracteata_E1','bracteata_E2','viridis_3','vesca_3','bracteata_3','mandschurica_1','mandschurica_2','mandschurica_3']\n",
    "# Function to convert tree file to NEXUS format and remove TaxLabels\n",
    "def convert_to_nexus(input_file, output_file):\n",
    "    # Read the trees from the input file\n",
    "    trees = list(Phylo.parse(input_file, 'newick'))\n",
    "    ##prune tree using a list of taxa\n",
    "    subtrees = list()\n",
    "    for tree in trees:\n",
    "        for taxon in prune_list:\n",
    "            if tree.find_any(name=taxon):\n",
    "                tree.prune(taxon)\n",
    "    # Write the trees to a temporary NEXUS file\n",
    "    temp_output_file = 'temp_output_file.nex'\n",
    "    Phylo.write(trees, temp_output_file, 'nexus')\n",
    "    \n",
    "    # Read the temporary NEXUS file\n",
    "    with open(temp_output_file, 'r') as file:\n",
    "        nexus_content = file.read()\n",
    "    \n",
    "    # Remove the TaxLabels block using regex\n",
    "    nexus_content = re.sub(r'Begin Taxa;.*?End;', '', nexus_content, flags=re.DOTALL)\n",
    "    \n",
    "    # Write the modified content to the final output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(nexus_content)\n",
    "\n",
    "# Example usage\n",
    "input_file = './Genetree/loci.treefile'  # replace with your input file name\n",
    "output_file = './PhyloNet/locitree_MPL.nex'  # replace with your desired output file name\n",
    "convert_to_nexus(input_file, output_file)\n",
    "phy_script = \"\"\"\n",
    "BEGIN PHYLONET;\n",
    "InferNetwork_MPL (all) 2 -pl 16 -di -x 100 -a <iinumae:iinumae_1,iinumae_2,iinumae_3;nilgerrensis:nilgerrensis_1,nilgerrensis_2;nipponica:nipponica_1,nipponica_2;bracteata1:americana,bracteata_F;bracteata2:bracteata_2,bracteata_4,bracteata_5;vesca:vesca_1,vesca_2,alba;viridis:viridis_1,viridis_2;octoploid_A:ananassa_A,chiloensis_A,virginiana_A;octoploid_B:ananassa_B,chiloensis_B,virginiana_B;octoploid_Ca:ananassa_Ca,chiloensis_Ca,virginiana_Ca;octoploid_Cb:ananassa_Cb,chiloensis_Cb,virginiana_Cb;Pmicrophylla:Pmicrophylla;Rchinensis:Rchinensis> ;\n",
    "InferNetwork_MPL (all) 3 -pl 16 -di -x 100 -a <iinumae:iinumae_1,iinumae_2,iinumae_3;nilgerrensis:nilgerrensis_1,nilgerrensis_2;nipponica:nipponica_1,nipponica_2;bracteata1:americana,bracteata_F;bracteata2:bracteata_2,bracteata_4,bracteata_5;vesca:vesca_1,vesca_2,alba;viridis:viridis_1,viridis_2;octoploid_A:ananassa_A,chiloensis_A,virginiana_A;octoploid_B:ananassa_B,chiloensis_B,virginiana_B;octoploid_Ca:ananassa_Ca,chiloensis_Ca,virginiana_Ca;octoploid_Cb:ananassa_Cb,chiloensis_Cb,virginiana_Cb;Pmicrophylla:Pmicrophylla;Rchinensis:Rchinensis> ;\n",
    "END;\n",
    "\"\"\"\n",
    "with open(output_file, 'a') as file1:\n",
    "    # Writing data to a file\n",
    "    file1.write(phy_script)\n",
    "##run PHYLONET\n",
    "##multiple alleles per sample did not work \n",
    "script = \"\"\"\n",
    "ml phylonet\n",
    "PhyloNet ./PhyloNet/locitree_MPL.nex\"\"\"\n",
    "script = slurm + script\n",
    "script_file = \"PhyloNetM.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fed795-5005-4f4d-9205-90650197bf2c",
   "metadata": {},
   "source": [
    "## Dsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c3925-fe1d-42b4-a0fc-dba4e0c90a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nl = pd.read_csv(\"treemix/name.clust\",sep = \"\\t\",header = None)\n",
    "nl = nl.iloc[:,1:3]\n",
    "nl.loc[nl[1]==\"Rchinensis\",2] = \"Outgroup\"\n",
    "nl.to_csv(\"Dsuite/sets.txt\",sep = \"\\t\",index=False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdf549-59bb-4e81-b876-d3afd4d586d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml = \"\\nml gcc/9.3.0 \\nml dsuite\"\n",
    "script = \"\\nDsuite Dtrios -c  -o Dsuite/32w -t Dsuite/species.tre SNP.32w.vcf.gz Dsuite/sets.txt\"\n",
    "script1 = slurm + ml + script\n",
    "script_file = \"Dsuite_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script1)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf1194-7c34-4255-bec5-65e3effa48cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = 'Dsuite/32w_tree.txt'\n",
    "file_path1 = 'Dsuite/32w_curated_tree.txt'\n",
    "# Read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "# Remove the special character\n",
    "content = content.replace('_', '')\n",
    "# Write the modified content back to the file\n",
    "with open(file_path1, 'w') as file:\n",
    "    file.write(content)\n",
    "# Define the file path\n",
    "file_path = 'Dsuite/species.tre'\n",
    "file_path1 = 'Dsuite/species_curated.tre'\n",
    "# Read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "# Remove the special character\n",
    "content = content.replace('_', '')\n",
    "# Write the modified content back to the file\n",
    "with open(file_path1, 'w') as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946875b8-64b7-462e-9849-a8c1352564d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fbranch \n",
    "ml = \"\\nml gcc/9.3.0 \\nml dsuite\"\n",
    "script = \"\\nDsuite Fbranch Dsuite/species.tre Dsuite/32w_tree.txt > Dsuite/32w_Fbranch.txt\"\"\"\n",
    "subprocess.run( ml+script, shell= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d558a8-2820-4193-ab27-e7d3525d2339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../popgen/Dsuite/Dsuite/utils/dtools.py  Dsuite/32w_Fbranch.txt Dsuite/species.tre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580de8e-bfd6-4341-8f5b-36a3fcf77347",
   "metadata": {},
   "source": [
    "## Dating using orthologs from whole genome assemblies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326d9ab-28a2-4b21-a4f3-6fb33325609a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##need to extract four subgenomes from whole genome assemblies\n",
    "##remove gene trees place viridis and octoploid genome together\n",
    "for s in [\"A\", \"B\",\"C\",\"D\"]:\n",
    "    with open(f'OtherGenomes/sub_{s}.list', 'w') as file:\n",
    "        # Loop through numbers 1 to 7\n",
    "        for i in range(1, 8):\n",
    "            # Write each number followed by 'A' to the file, with each on a new line\n",
    "            file.write(f\"-{i}{s}-\\n\")\n",
    "    script = f\"\"\"ml seqkit\n",
    "    seqkit grep -n -r -f OtherGenomes/sub_{s}.list OtherGenomes/Fchil_hap1.pep.fa -o OtherGenomes/Fchil_{s}.fa\"\"\"\n",
    "    subprocess.run(script,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ba67d-ad67-48ab-a3b4-013f137ecee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orth = \"\"\"\n",
    "ml orthofinder\n",
    "orthofinder -f OtherGenomes\n",
    "\"\"\"\n",
    "script = slurm + orth\n",
    "script_file = \"Orthofinder_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8295b-ef75-46bf-9c5b-e65cd0fcdff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the tree files\n",
    "directory = r\"/orange/vwhitaker/zhen/Polyorigin/OtherGenomes/OrthoFinder/Results_Nov14_1/Gene_Trees/\"\n",
    "# Create a dictionary to store trees\n",
    "trees = {}\n",
    "##only retain single copy genes\n",
    "single_cp = os.listdir(r\"/orange/vwhitaker/zhen/Polyorigin/OtherGenomes/OrthoFinder/Results_Nov14_1/Single_Copy_Orthologue_Sequences/\")\n",
    "single_cp1 = [re.sub(\".fa\",\"_tree.txt\",string) for string in single_cp]\n",
    "# Iterate over each file in the directory\n",
    "for filename in single_cp1:\n",
    "    if filename.endswith(\".txt\"):  # Assuming the files are in Newick format and have .tre extension\n",
    "        # Construct the full file path\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load the tree from the file\n",
    "        tree = dendropy.Tree.get(\n",
    "            path=filepath,\n",
    "            schema=\"newick\",  # Change this if your tree files are in a different format\n",
    "            preserve_underscores = True\n",
    "        )\n",
    "\n",
    "        # Store the tree with the filename as the key\n",
    "        trees[filename] = tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ced0b-f972-4e4a-b462-fc7b05b538b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_occurrence_with_in(lst, pattern):\n",
    "    for item in lst:\n",
    "        if pattern in item:\n",
    "            return item\n",
    "    return None  # Pattern not found in any element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063114e3-76d3-4616-8fe9-54bff0679b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_adm = []\n",
    "for id1, tree in trees.items():\n",
    "    print(id1)\n",
    "    labels = [node.label for node in tree.taxon_namespace]\n",
    "    pat_4 = [\"Potentilla_proteins\",\"Fviridis2_pep\", \"Fragaria_vesca_v4\", \"Fvirg_A\"]\n",
    "    t_labels = [find_first_occurrence_with_in(labels, pat) for pat in pat_4]\n",
    "    tree1 = tree.extract_tree()\n",
    "    tree1.retain_taxa_with_labels(t_labels,update_bipartitions=True)\n",
    "    tns=tree1.taxon_namespace\n",
    "    t1 = \"('{}',('{}',('{}','{}')));\".format(t_labels[0],t_labels[1],t_labels[2],t_labels[3])\n",
    "    Atree1 = dendropy.Tree.get(\n",
    "            data=t1,\n",
    "            schema='newick',\n",
    "            taxon_namespace=tns)\n",
    "    if treecompare.symmetric_difference(Atree1, tree1)==0:\n",
    "        non_adm.append(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a17d8-33b4-42f4-a94e-8951421ba4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save outputs to file\n",
    "non_adm_df = pd.DataFrame(non_adm)\n",
    "single_orthlogs = non_adm_df[0].str.extract('(OG.+)_.+')\n",
    "single_orthlogs.to_csv('singleOrthologsWOadmixture.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1999762-1cb8-4d62-805c-b9c30f259df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##change names, laad all functions\n",
    "New_names=[\"Fchil_A\",\"Fchil_B\",\"Fchil_C\",\"Fchil_D\",\"Fmanchurica\",\"Fnilgerrensis\", \"Fnipponica\",\"Fiinumae\", \"Fvesca_H\",\n",
    "         \"Fvesca_R\",\"Fvirg_A\",\"Fvirg_B\",\"Fvirg_C\",\"Fvirg_D\",\"Fviridis1\",\"Fviridis2\",\"Pmicrantha\",\"Rchinensis\"]\n",
    "single_orth = pd.read_csv('singleOrthologsWOadmixture.csv')\n",
    "single_arr = single_orth.to_numpy()\n",
    "def modify_sequence_names(records, new_names):\n",
    "    for i, record in enumerate(records):\n",
    "        if i < len(new_names):\n",
    "            record.id = new_names[i]\n",
    "            record.description = \"\"\n",
    "        else:\n",
    "            break           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34968c43-225b-40d9-9fb2-239628db6ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##create raw fasta files for non-admixed orthlogs \n",
    "dir = r\"/orange/vwhitaker/zhen/Polyorigin/OtherGenomes/OrthoFinder/Results_Nov14_1/Single_Copy_Orthologue_Sequences/\"\n",
    "out_dir = r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/raw/\"\n",
    "for orth in single_arr:\n",
    "    fasta_file = os.path.join(dir, orth[0] + \".fa\")\n",
    "    records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    modify_sequence_names(records, New_names)\n",
    "    with open(out_dir+orth[0]+\".fasta\", \"w\") as output_handle:\n",
    "        SeqIO.write(records, output_handle, \"fasta\")\n",
    "    print(\"Modified FASTA file created:\", orth+\".fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5c651-b47c-44c1-a5fd-2ba9fa8d0da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##MAFFT alignment \n",
    "ml = \"\"\"\n",
    "ml mafft\n",
    "\"\"\"\n",
    "single_fa = os.listdir(out_dir)\n",
    "out_mafft =  r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/MAFFT/\"\n",
    "for file in single_fa:\n",
    "    script = slurm + ml+\"mafft {} > {}\".format(out_dir+file,out_mafft+file) \n",
    "    script_file = file + \".sh\"\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)\n",
    "    subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61413b0-7389-416a-95bc-86d90a9b03c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##create MAFFT alignment for all single copy orthologs\n",
    "single_cp = os.listdir(r\"/orange/vwhitaker/zhen/Polyorigin/OtherGenomes/OrthoFinder/Results_Nov14_1/Single_Copy_Orthologue_Sequences/\")\n",
    "dir = r\"/orange/vwhitaker/zhen/Polyorigin/OtherGenomes/OrthoFinder/Results_Nov14_1/Single_Copy_Orthologue_Sequences/\"\n",
    "out_dir = r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/singlecopy/\"\n",
    "for file in single_cp:\n",
    "    records = list(SeqIO.parse(dir+file, \"fasta\"))\n",
    "    modify_sequence_names(records, New_names)\n",
    "    with open(out_dir+file, \"w\") as output_handle:\n",
    "        SeqIO.write(records, output_handle, \"fasta\")\n",
    "    print(\"Modified FASTA file created:\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577a083-3a53-4417-99ce-751b4845aba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##MAFFT alignment \n",
    "ml = \"\"\"\n",
    "ml mafft\n",
    "\"\"\"\n",
    "single_fa = os.listdir(out_dir)\n",
    "out_mafft =  r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/MAFFT_singlecopy/\"\n",
    "for file in single_fa:\n",
    "    script = slurm + ml+\"mafft {} > {}\".format(out_dir+file,out_mafft+file) \n",
    "    script_file = file + \".sh\"\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)\n",
    "    subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2739381-2ce5-4972-875f-6a2283542bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##concatenate non-admixed MAFFT outputs\n",
    "# Dictionary to store sequences by name\n",
    "concatenated_sequences = {}\n",
    "input_files = os.listdir(out_mafft)\n",
    "output_file = r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/concatenated_singlecopy.fasta\"\n",
    "# Iterate through input files and store sequences by name\n",
    "for input_file in input_files:\n",
    "    with open(out_mafft+input_file, \"r\") as fasta_file:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            seq_name = record.id\n",
    "            if seq_name not in concatenated_sequences:\n",
    "                concatenated_sequences[seq_name] = \"\"\n",
    "            concatenated_sequences[seq_name] += str(record.seq)\n",
    "\n",
    "# Write the concatenated sequences to the output file\n",
    "with open(output_file, \"w\") as output_handle:\n",
    "    for seq_name, sequence in concatenated_sequences.items():\n",
    "        output_handle.write(f\">{seq_name}\\n{sequence}\\n\")\n",
    "\n",
    "print(\"Concatenated FASTA file created:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9cd2f1-7185-4692-bba6-60f186d9c0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated FASTA file created: /orange/vwhitaker/zhen/Polyorigin/speciestree/concatenated_noAdmix.fasta\n"
     ]
    }
   ],
   "source": [
    "##concatenate nonadmixed multiple MAFFT outputs\n",
    "# Dictionary to store sequences by name\n",
    "concatenated_sequences = {}\n",
    "out_mafft =  r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/MAFFT/\"\n",
    "input_files = os.listdir(out_mafft)\n",
    "output_file = r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/concatenated_noAdmix.fasta\"\n",
    "# Iterate through input files and store sequences by name\n",
    "for input_file in input_files:\n",
    "    with open(out_mafft+input_file, \"r\") as fasta_file:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            seq_name = record.id\n",
    "            if seq_name not in concatenated_sequences:\n",
    "                concatenated_sequences[seq_name] = \"\"\n",
    "            concatenated_sequences[seq_name] += str(record.seq)\n",
    "\n",
    "# Write the concatenated sequences to the output file\n",
    "with open(output_file, \"w\") as output_handle:\n",
    "    for seq_name, sequence in concatenated_sequences.items():\n",
    "        output_handle.write(f\">{seq_name}\\n{sequence}\\n\")\n",
    "\n",
    "print(\"Concatenated FASTA file created:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6d362-4803-4761-a683-f6e7658b4698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##build a new fasttree using the non-admixed genes\n",
    "single_orth = pd.read_csv('singleOrthologsWOadmixture.csv')\n",
    "single_arr = single_orth.to_numpy()\n",
    "dir1=r\"/orange/vwhitaker/zhen/Polyorigin/OtherGenomes/OrthoFinder/Results_Nov14_1/Gene_Trees/\"\n",
    "\n",
    "# Output file name\n",
    "output_file = r\"/orange/vwhitaker/zhen/Polyorigin/speciestree/Astral/nonAdmix_gene_trees.txt\"\n",
    "\n",
    "New_names=[\"Fchil_A\",\"Fchil_B\",\"Fchil_C\",\"Fchil_D\",\"Fmanchurica\",\"Fnilgerrensis\", \"Fnipponica\",\"Fiinumae\", \"Fvesca_H\",\n",
    "         \"Fvesca_R\",\"Fvirg_A\",\"Fvirg_B\",\"Fvirg_C\",\"Fvirg_D\",\"Fviridis1\",\"Fviridis2\",\"Pmicrantha\",\"Rchinensis\"]\n",
    "patterns_and_replacements = [\n",
    "    ('Fchil_A[^:]+:', 'Fchil_A:'),\n",
    "    ('Fchil_B[^:]+:', 'Fchil_B:'),\n",
    "    ('Fchil_C[^:]+:', 'Fchil_C:'),\n",
    "    ('Fchil_D[^:]+:', 'Fchil_D:'),\n",
    "    ('Fmanchurica[^:]+:', 'Fmanchurica:'),\n",
    "    ('Fnilgerrensis[^:]+:', 'Fnilgerrensis:'),\n",
    "    ('Fnip[^:]+:', 'Fnipponica:'),\n",
    "    ('Fragaria_iinumae[^:]+:', 'Fiinumae:'),\n",
    "    ('Fragaria_vesca_v4[^:]+:', 'Fvesca_H:'),\n",
    "    ('Fvesca_CFRA2339[^:]+:', 'Fvesca_R:'),\n",
    "    ('Fvirg_A[^:]+:', 'Fvirg_A:'),\n",
    "    ('Fvirg_B[^:]+:', 'Fvirg_B:'),\n",
    "    ('Fvirg_C[^:]+:', 'Fvirg_C:'),\n",
    "    ('Fvirg_D[^:]+:', 'Fvirg_D:'),\n",
    "    ('Fviridis.pep[^:]+:', 'Fviridis1:'),\n",
    "    ('Fviridis2.pep[^:]+:', 'Fviridis2:'),\n",
    "    ('Potentilla_proteins[^:]+:', 'Pmicrantha:'),\n",
    "    ('Rosa_chinensis[^:]+:', 'Rchinensis:'),\n",
    "]\n",
    "# Function to perform the substitutions\n",
    "def substitute_patterns(input_string, patterns_and_replacements):\n",
    "    for pattern, replacement in patterns_and_replacements:\n",
    "        input_string = re.sub(pattern, replacement, input_string)\n",
    "    return input_string\n",
    "# Open the output file in write mode\n",
    "with open(output_file, \"w\") as output:\n",
    "    for file_name in single_arr:\n",
    "        try:\n",
    "            # Open each input file in read mode\n",
    "            filename= dir1 + file_name[0]+\"_tree.txt\"\n",
    "            with open(filename, \"r\") as input_file:\n",
    "                # Read the contents of the input file\n",
    "                file_contents = input_file.read()\n",
    "                #substitution\n",
    "                file_contents = substitute_patterns(file_contents, patterns_and_replacements)\n",
    "                # Write the contents to the output file\n",
    "                output.write(file_contents+\"\\n\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa04eb1-aa65-4186-aba4-f9d3d40459c8",
   "metadata": {},
   "source": [
    "## R8S with bootstrapping results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6ad2c-5dad-4bf3-9bfc-18d0191fa862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##create bootstrap datasets\n",
    "import random\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# Load the alignment from a PHYLIP file\n",
    "alignment = AlignIO.read(\"/orange/vwhitaker/zhen/Polyorigin/speciestree/concatenated.fasta\", \"fasta\")\n",
    "num_columns = alignment.get_alignment_length()\n",
    "num_replicates = 100\n",
    "\n",
    "# Generate 100 bootstrap replicates\n",
    "for i in range(1, num_replicates + 1):\n",
    "    # Create a new alignment by resampling columns with replacement\n",
    "    bootstrap_columns = [random.randint(0, num_columns - 1) for _ in range(num_columns)]\n",
    "    bootstrap_alignment = MultipleSeqAlignment(\n",
    "        [\n",
    "            SeqRecord(\"\".join(record.seq[j] for j in bootstrap_columns), id=record.id)\n",
    "            for record in alignment\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save the bootstrap replicate to a new PHYLIP file\n",
    "    AlignIO.write(bootstrap_alignment, f\"speciestree/r8s/bootstrap_noAdmix_{i}.phy\", \"phylip-relaxed\")\n",
    "\n",
    "    print(f\"Bootstrap replicate {i} saved as bootstrap_noAdmix_{i}.phy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3babb2-b8d6-40c5-901a-482bf57e0951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##calculate bootstrap ML tree using iqtreez\n",
    "num_replicates = 100\n",
    "for i in range(1, num_replicates + 1):\n",
    "    ml = \"\\nml iq-tree\"\n",
    "    script = f\"\\niqtree -s speciestree/r8s/bootstrap_noAdmix_{i}.phy -te speciestree/nonAdmix_Astral_1.tre -m JTT+F+I+R8 -pre speciestree/nonAdmix_Astral_1.tre -o Rchinensis --prefix speciestree/r8s/boot.{i}.nonAdmix 2>speciestree/r8s/out.{i}.nonadmix.boot.log\"\n",
    "    script = slurm +ml + script\n",
    "    script_file = f\"R8S_boot_script_nonadmix.{i}.sh\"\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)\n",
    "    subprocess.run(['sbatch',script_file])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8ad67-c041-41a6-8aaa-b31123d6677b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# Load the alignment from a PHYLIP file\n",
    "alignment = AlignIO.read(\"/orange/vwhitaker/zhen/Polyorigin/speciestree/concatenated_singlecopy.fasta\", \"fasta\")\n",
    "num_columns = alignment.get_alignment_length()\n",
    "num_replicates = 100\n",
    "\n",
    "# Generate 100 bootstrap replicates\n",
    "for i in range(1, num_replicates + 1):\n",
    "    # Create a new alignment by resampling columns with replacement\n",
    "    bootstrap_columns = [random.randint(0, num_columns - 1) for _ in range(num_columns)]\n",
    "    bootstrap_alignment = MultipleSeqAlignment(\n",
    "        [\n",
    "            SeqRecord(\"\".join(record.seq[j] for j in bootstrap_columns), id=record.id)\n",
    "            for record in alignment\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save the bootstrap replicate to a new PHYLIP file\n",
    "    AlignIO.write(bootstrap_alignment, f\"speciestree/r8s/bootstrap_singlecopy_{i}.phy\", \"phylip-relaxed\")\n",
    "\n",
    "    print(f\"Bootstrap replicate {i} saved as bootstrap_singlecopy_{i}.phy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef4b39-d3a1-468b-b0fa-9579830e2b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 100 bootstrap alignments were created using seqboot in phylip\n",
    "##calculate bootstrap ML tree using iqtreez\n",
    "num_replicates = 100\n",
    "for i in range(1, num_replicates + 1):\n",
    "    ml = \"\\nml iq-tree\"\n",
    "    script = f\"\\niqtree -s speciestree/r8s/bootstrap_singlecopy_{i}.phy -te speciestree/Astral/astral_tree_rooted_allsingle.txt -m JTT+F+I+R8 -pre speciestree/Astral/astral_tree_rooted_allsingle.txt -o Rchinensis --prefix speciestree/r8s/boot.{i}.singlecopy 2>speciestree/r8s/out.{i}.singlecopy.boot.log\"\n",
    "    script = slurm +ml + script\n",
    "    script_file = f\"R8S_boot_script_singlecopy.{i}.sh\"\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)\n",
    "    subprocess.run(['sbatch',script_file])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4900cc1-0e0f-43aa-a4c2-0b7d99ce76b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## prepare input file for R8s\n",
    "from Bio import Phylo\n",
    "from io import StringIO\n",
    "\n",
    "# Load the trees\n",
    "trees = []\n",
    "for i in range(1, 101):  # Assuming 100 files named tree1.newick, tree2.newick, ..., tree100.newick\n",
    "    tree = Phylo.read(f'speciestree/r8s/boot.{i}.singlecopy.treefile', 'newick')\n",
    "    # Specify the outgroup (e.g., a specific taxon name)\n",
    "    outgroup = tree.find_any(name='Rchinensis')\n",
    "\n",
    "    # Root the tree using the outgroup\n",
    "    tree.root_with_outgroup(outgroup)\n",
    "    trees.append(tree)\n",
    "\n",
    "# Write the trees to a Nexus file without a TAXA block\n",
    "with open('speciestree/r8s/r8s.boot.singlecopy.nex', 'w') as nexus_file:\n",
    "    nexus_file.write(\"#NEXUS\\n\\nBEGIN TREES;\\n\")\n",
    "    for idx, tree in enumerate(trees, start=1):\n",
    "        tree_str = StringIO()\n",
    "        Phylo.write(tree, tree_str, \"newick\")\n",
    "        tree_newick = tree_str.getvalue().strip()\n",
    "        nexus_file.write(f\"\\tTREE tree_{idx} = {tree_newick}\\n\")\n",
    "    nexus_file.write(\"END;\\n\")\n",
    "\n",
    "r8s_com = \"\"\"\n",
    "begin r8s;\n",
    "blformat lengths=persite nsites=647966 ultrametric=no;\n",
    "MRCA node1 Pmicrantha Rchinensis;\n",
    "MRCA node2 Pmicrantha Fchil_B;\n",
    "MRCA node3 Fnilgerrensis Fviridis1;\n",
    "MRCA node4 Fchil_A Fvesca_R;\n",
    "MRCA node5 Fchil_C Fchil_D;\n",
    "MRCA node6 Fiinumae Fvirg_B;\n",
    "constrain taxon=node1 max_age=55;\n",
    "fixage taxon=node2 age=23;\n",
    "constrain taxon=node3 min_age=2.6;\n",
    "divtime method=pl algorithm=tn;\n",
    "showage;\n",
    "profile taxon=node4 parameter=age;\n",
    "profile taxon=node5 parameter=age;\n",
    "profile taxon=node6 parameter=age;\n",
    "describe plot=tree_description;\n",
    "end;\n",
    "\"\"\"\n",
    "with open(\"speciestree/r8s/r8s.boot.singlecopy.nex\", \"a\") as f:\n",
    "    f.write(r8s_com)\n",
    "\n",
    "##to run r8s\n",
    "##command line\n",
    "##r8s -b -f r8s.boot.singlecopy.nex > r8s.boot.result.singlecopy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca43ede5-1f5b-4c98-a9c9-a0c9fa91c9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## prepare input file for R8s\n",
    "from Bio import Phylo\n",
    "from io import StringIO\n",
    "\n",
    "# Load the trees\n",
    "trees = []\n",
    "for i in range(1, 101):  # Assuming 100 files named tree1.newick, tree2.newick, ..., tree100.newick\n",
    "    tree = Phylo.read(f'speciestree/r8s/boot.{i}.nonAdmix.treefile', 'newick')\n",
    "    # Specify the outgroup (e.g., a specific taxon name)\n",
    "    outgroup = tree.find_any(name='Rchinensis')\n",
    "\n",
    "    # Root the tree using the outgroup\n",
    "    tree.root_with_outgroup(outgroup)\n",
    "    trees.append(tree)\n",
    "\n",
    "# Write the trees to a Nexus file without a TAXA block\n",
    "with open('speciestree/r8s/r8s.boot.noAdmix.nex', 'w') as nexus_file:\n",
    "    nexus_file.write(\"#NEXUS\\n\\nBEGIN TREES;\\n\")\n",
    "    for idx, tree in enumerate(trees, start=1):\n",
    "        tree_str = StringIO()\n",
    "        Phylo.write(tree, tree_str, \"newick\")\n",
    "        tree_newick = tree_str.getvalue().strip()\n",
    "        nexus_file.write(f\"\\tTREE tree_{idx} = {tree_newick}\\n\")\n",
    "    nexus_file.write(\"END;\\n\")\n",
    "\n",
    "r8s_com = \"\"\"\n",
    "begin r8s;\n",
    "blformat lengths=persite nsites=487377 ultrametric=no;\n",
    "MRCA node1 Pmicrantha Rchinensis;\n",
    "MRCA node2 Pmicrantha Fchil_B;\n",
    "MRCA node3 Fnilgerrensis Fviridis1;\n",
    "MRCA node4 Fchil_A Fvesca_R;\n",
    "MRCA node5 Fchil_C Fchil_D;\n",
    "MRCA node6 Fiinumae Fvirg_B;\n",
    "constrain taxon=node1 max_age=55;\n",
    "fixage taxon=node2 age=23;\n",
    "constrain taxon=node3 min_age=2.6;\n",
    "divtime method=pl algorithm=tn;\n",
    "showage;\n",
    "profile taxon=node4 parameter=age;\n",
    "profile taxon=node5 parameter=age;\n",
    "profile taxon=node6 parameter=age;\n",
    "describe plot=tree_description;\n",
    "end;\n",
    "\"\"\"\n",
    "with open(\"speciestree/r8s/r8s.boot.noAdmix.nex\", \"a\") as f:\n",
    "    f.write(r8s_com)\n",
    "\n",
    "##to run r8s\n",
    "##command line\n",
    "##r8s -b -f r8s.boot.noAdmix.nex > r8s.boot.result.noAdmix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb7df3-d890-4f04-bf32-72cce48423c3",
   "metadata": {},
   "source": [
    "# Build an Astral with non-admixed orthologs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b83a75-cd7e-41b5-a154-0859a734e233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script = \"\"\"ml astral\n",
    "astral -i /orange/vwhitaker/zhen/Polyorigin/speciestree/Astral/nonAdmix_gene_trees.txt -o /orange/vwhitaker/zhen/Polyorigin/speciestree/Astral/nonAdmix_Astral.tre 2>/orange/vwhitaker/zhen/Polyorigin/speciestree/Astral/out.log\"\"\"\n",
    "print(script)\n",
    "subprocess(script, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9226f9c7-4829-4b9b-a2dd-708e53ec095d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 42217709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', 'iqtree_script.sh'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script = \"\"\"ml iq-tree\n",
    "iqtree -s speciestree/concatenated.fasta -te speciestree/Astral/nonAdmix_Astral.tre -pre speciestree/Astral/nonAdmix_Astral.tre --prefix speciestree/iqtree\"\"\"\n",
    "script = slurm + script\n",
    "script_file = \"iqtree_script.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690fddc-2be7-4bfd-9d73-fc1ddd297f79",
   "metadata": {},
   "source": [
    "## Dating with LSD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996fa88-6579-475b-92be-512fe73e7d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml = \"\\nml iq-tree\"\n",
    "script = \"\\niqtree -s speciestree/concatenated_singlecopy.fasta -m JTT+F+I+R8 --date speciestree/LSD2/date.txt --date-tip 0 -o Rchinensis --date-ci 100 -te speciestree/Astral/nonAdmix_Astral.tre --prefix speciestree/LSD2/lsd.singlecopy --redo 2>speciestree/LSD2/out.singlecopy.log\"\n",
    "script = slurm +ml + script\n",
    "script_file = \"LSD2_script_singlecopy.sh\"\n",
    "with open(script_file, \"w\") as f:\n",
    "    f.write(script)\n",
    "subprocess.run(['sbatch',script_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee1b03-5ae3-43e3-8c28-c0163ae550a2",
   "metadata": {},
   "source": [
    "## Find HE using short-reads of bracteata samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab50501-c10b-4cff-9988-73f757f974a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular alignment only retain best alignment\n",
    "index_dir = \"/orange/vwhitaker/zhen/popgen/farr1_index/\"\n",
    "filtered_df = df[df.iloc[:,1].str.contains('bracteata')]\n",
    "for index, row in filtered_df.iterrows():\n",
    "    if os.path.isfile('./Diploid_align_octoploid/{}.bam'.format(row[0])):\n",
    "        print('./Diploid_align_octoploid/{}.bam exists'.format(row[0]))\n",
    "    else:    \n",
    "        if pd.isna(row['File3']) == True:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} -pre- -so -o ./Diploid_align_octoploid/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],id=row[0])\n",
    "        else:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} {file3} {file4} -pre- -so -o ./Diploid_align_octoploid/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],\n",
    "                                                                                                                                        file3=row['File3'],file4=row['File4'],id=row[0])\n",
    "        script_file = \"{}_SNAP.sh\".format(row[0])\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script)\n",
    "        result = subprocess.run(['sbatch', script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c5365-6fb7-4a99-bd7c-883bb7f99274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get chromosome sizes using seqkit\n",
    "script = \"\"\"ml seqkit\n",
    "seqkit fx2tab /blue/vwhitaker/fanzhen/asm/farr1.fa -n -l > farr1.chrlength.txt\"\"\"\n",
    "subprocess.run(script,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e222d-9cbf-4c77-ab46-8c0cb96884c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the window file needed for coverage count\n",
    "chromosome_sizes_file = \"farr1.chrlength.txt\"\n",
    "chromosome_sizes = {}\n",
    "with open(chromosome_sizes_file, 'r') as f:\n",
    "    for line in f:\n",
    "        chrom, size = line.strip().split('\\t')\n",
    "        chromosome_sizes[chrom] = int(size)\n",
    "\n",
    "window_size = 10000  # Specify the window size here\n",
    "\n",
    "with open('farr1.regions.bed', 'w') as bed_file:\n",
    "    for chrom, size in chromosome_sizes.items():\n",
    "        for start in range(0, size, window_size):\n",
    "            end = min(start + window_size, size)\n",
    "            bed_file.write(f'{chrom}\\t{start}\\t{end}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7813ceaf-eb3f-4336-99f3-b904bac99fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 37739728\n",
      "Submitted batch job 37739729\n",
      "Submitted batch job 37739730\n"
     ]
    }
   ],
   "source": [
    "bam_files = glob.glob(\"./Diploid_align_octoploid\" + '/*.bam')\n",
    "ml = \"ml samtools\\n\"\n",
    "script = \"samtools bedcov farr1.regions.bed {} > {}\"\n",
    "for bam_file in bam_files: \n",
    "    script_full = slurm + ml + script.format(bam_file,bam_file+\".txt\")\n",
    "    script_file = \"{}_bedcov.sh\".format(bam_file).replace(\"./Diploid_align_octoploid/\", \"\")\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script_full)\n",
    "    result = subprocess.run(['sbatch', script_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f8c28-7fee-4cf4-ab3b-c537e5610651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in filtered_df.iterrows():\n",
    "    if os.path.isfile('./Diploid_align_octoploid/{}.bam'.format(row[0])):\n",
    "        print('./Diploid_align_octoploid/{}.bam exists'.format(row[0]))\n",
    "    else:    \n",
    "        if pd.isna(row['File3']) == True:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} -pre- -so -o ./Diploid_align_octoploid/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],id=row[0])\n",
    "        else:\n",
    "            script = slurm + \"\\nml snap/2.0.3\" + \"\\nsnap-aligner paired {index_dir} {file1} {file2} {file3} {file4} -pre- -so -o ./Diploid_align_octoploid/{id}.bam\".format(index_dir = index_dir,file1 = row['File1'],file2=row['File2'],\n",
    "                                                                                                                                        file3=row['File3'],file4=row['File4'],id=row[0])\n",
    "        script_file = \"{}_SNAP.sh\".format(row[0])\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(script)\n",
    "        result = subprocess.run(['sbatch', script_file])\n",
    "##data analyses were done in Rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fdb78b-6e73-481a-9172-5893c047195f",
   "metadata": {},
   "source": [
    "## Find synteny regions in F. Vesca genome for gene trees in the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326bfbc-8a6b-4784-8393-cac64e407615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##genome alignment to find Synteny regions\n",
    "\n",
    "df1 = pd.read_csv(\"Diploid_align_octoploid/introgress_vesca_coords.txt\",delimiter=\"\\t\",header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc2afd-ea8c-4372-8446-fca8eb3fd2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "ml bcftools\n",
    "bcftools view -r {chr}:{start}-{end} SNP.40w.vcf.gz -Oz > Diploid_align_octoploid/regiontree/{chr}_{start}_{end}.vcf.gz\n",
    "ml python\n",
    "python ../popgen/vcf2phylip/vcf2phylip/vcf2phylip.py -i Diploid_align_octoploid/regiontree/{chr}_{start}_{end}.vcf.gz \n",
    "ml iq-tree\n",
    "iqtree2 -s {chr}_{start}_{end}.min4.phy -B 1000 -T AUTO --prefix Diploid_align_octoploid/regiontree/{chr}_{start}_{end} -alrt 1000 -m MFP -T AUTO -redo\n",
    "\"\"\"\n",
    "for index, row in df1.iterrows():\n",
    "    chrid= row[0]\n",
    "    start = row[1]\n",
    "    end = row[2]\n",
    "    script1 = slurm + script.format(chr = chrid, start = start, end = end)\n",
    "    script_file = \"{}_{}_tree.sh\".format(chrid, start)\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script1)\n",
    "    result = subprocess.run(['sbatch', script_file])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFRC Python-3.10",
   "language": "python",
   "name": "python3-3.10-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
